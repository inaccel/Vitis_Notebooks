{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from queue import Queue\n",
    "import cv2 as cv\n",
    "import inaccel.coral as inaccel\n",
    "import io\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import threading\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ndarrays for the constant parameters of the accelerator\n",
    "to help the scheduling we create one copy of each array for each request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req_num = 4\n",
    "\n",
    "cameraMA_l = []\n",
    "cameraMA_r = []\n",
    "distC_l = []\n",
    "distC_r = []\n",
    "irA_l = []\n",
    "irA_r = []\n",
    "bm_state_arr = []\n",
    "\n",
    "with inaccel.allocator:\n",
    "    for j in range(req_num):\n",
    "        cameraMA_l.append(np.array([933.173, 0.0, 663.451, 0.0, 933.173, 377.015, 0.0, 0.0, 1.0], dtype = np.float32))\n",
    "        cameraMA_r.append(np.array([933.467, 0.0, 678.297, 0.0, 933.467, 359.623, 0.0, 0.0, 1.0], dtype = np.float32))\n",
    "\n",
    "        distC_l.append(np.array([-0.169398, 0.0227329, 0.0, 0.0, 0.0], dtype = np.float32))\n",
    "        distC_r.append(np.array([-0.170581, 0.0249444, 0.0, 0.0, 0.0], dtype = np.float32))\n",
    "\n",
    "        irA_l.append(np.array([0.0011976323, -0.0000000019, -0.8153011732, 0.0000000007, 0.0011976994, \\\n",
    "                               -0.4422348617,  0.0000126839,  0.0000001064, 0.9913820905], dtype = np.float32))\n",
    "        irA_r.append(np.array([0.0011976994,  0.0000000000, -0.8047567905, -0.0000000000, 0.0011976994, \\\n",
    "                               -0.4420566166, -0.0000000000, -0.0000001064,  1.0000392898], dtype = np.float32))\n",
    "\n",
    "        bm_state_arr.append(np.array([0, 15, 31, 15, 0, 48, 20, 15, 16, 3, 0], dtype = np.int32))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "                                  +-------------+          +------------+\n",
    "                                  |             |_ __ __ __|            |\n",
    "                                  |  submitter  |_O__O__O__|   waiter   |\n",
    "                                  |             |          |            |\n",
    "                                  +-------------+          +------------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submitter():\n",
    "    for i in range(frame_num):\n",
    "        # try to read a new frame\n",
    "        ret, frame = input_stream.read()\n",
    "        if (ret == False):\n",
    "            queue.put((None, None, None, None, None))\n",
    "            break\n",
    "            \n",
    "        # split the frame in two, one for the left and one for the right image\n",
    "        frame_left = cv.cvtColor(frame[:height, :, :], cv.COLOR_BGR2GRAY)\n",
    "        frame_right = cv.cvtColor(frame[height:, :, :], cv.COLOR_BGR2GRAY)\n",
    "\n",
    "        with inaccel.allocator:\n",
    "            # convert the two frames to inaccel ndarrays and allocate the output array\n",
    "            left_mat = np.array(frame_left)\n",
    "            right_mat = np.array(frame_right)\n",
    "            disp_mat = np.ndarray((height, width), dtype = np.uint16)\n",
    "\n",
    "        # describe a new request\n",
    "        req = inaccel.request('com.xilinx.vitis.vision.stereoBM')\n",
    "        req.arg(left_mat)\n",
    "        req.arg(right_mat)\n",
    "        req.arg(disp_mat)\n",
    "        req.arg(cameraMA_l[i % req_num])\n",
    "        req.arg(cameraMA_r[i % req_num])\n",
    "        req.arg(distC_l[i % req_num])\n",
    "        req.arg(distC_r[i % req_num])\n",
    "        req.arg(irA_l[i % req_num])\n",
    "        req.arg(irA_r[i % req_num])\n",
    "        req.arg(bm_state_arr[i % req_num])\n",
    "        req.arg(np.int32(height))\n",
    "        req.arg(np.int32(width))\n",
    "        \n",
    "        # try to submit that request\n",
    "        try:\n",
    "            future = inaccel.submit(req)\n",
    "        except RuntimeError:\n",
    "            print(\"Cannot connect to the Docker daemon. Is InAccel Coral running?\")\n",
    "\n",
    "            queue.put((None, None, None, None, None))\n",
    "            break\n",
    "        \n",
    "        # wait while the queue is full\n",
    "        while queue.full():\n",
    "            time.sleep(0.01)\n",
    "            \n",
    "        # push the future reference as well as the ndarrays to the queue\n",
    "        queue.put((future, left_mat, right_mat, disp_mat, frame))\n",
    "        \n",
    "        # update the queue status\n",
    "        queue_status.value = queue.qsize() / queue_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def waiter():\n",
    "    for i in tqdm(range(frame_num)):\n",
    "        start = time.time() * 1000\n",
    "        \n",
    "        # try to pop from the queue\n",
    "        future, left_mat, right_mat, disp_mat, frame = queue.get()\n",
    "        if (future == None):\n",
    "            break\n",
    "\n",
    "        # convert the array to an image and write it to the widget\n",
    "        if (print_input):\n",
    "            frame = cv.resize(frame[:height, :, :], (int(width / scale_down), int(height / scale_down)))\n",
    "            frame_img = PIL.Image.fromarray(frame)\n",
    "            f = io.BytesIO()\n",
    "            frame_img.save(f, format = 'jpeg')\n",
    "            image_in.value = f.getvalue()\n",
    "            image_in.width = int(width / scale_down)\n",
    "            image_in.height = int(height / scale_down)\n",
    "        \n",
    "        # wait for the future to complete\n",
    "        future.result()\n",
    "        \n",
    "        if (print_output):\n",
    "            # normalize the output array\n",
    "            disp_img = disp_mat.view(np.ndarray).astype(np.uint8)\n",
    "            disp_img = cv.resize(cv.cvtColor(disp_img, cv.COLOR_GRAY2BGR), (int(width / scale_down), int(height / scale_down)))\n",
    "\n",
    "            # convert the array to an image and write it to the widget\n",
    "            disp_img = PIL.Image.fromarray(disp_img)\n",
    "            f = io.BytesIO()\n",
    "            disp_img.save(f, format = 'jpeg')\n",
    "            image_out.value = f.getvalue()\n",
    "            image_out.width = int(width / scale_down)\n",
    "            image_out.height = int(height / scale_down)        \n",
    "        \n",
    "        # explicitly delete the inaccel ndarrays\n",
    "        # this step is not necessary, as the will be garbage collected\n",
    "        # but it helps free earlier the corresponding device memory\n",
    "        del left_mat\n",
    "        del right_mat\n",
    "        del disp_mat\n",
    "        \n",
    "        # if sync_output is true, sleep until it's time for the next frame\n",
    "        if (sync_output):\n",
    "            while ((time.time() * 1000) - start < millis_per_frame):\n",
    "                time.sleep(0.000001)\n",
    "        \n",
    "        # update the queue status\n",
    "        queue.task_done()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_video = 'data/bbb_sunflower_1080p_30fps_stereo_abl.mp4'\n",
    "queue_size = 16 # not necessary, but it helps with resource management\n",
    "sync_output = False # force output framerate to be close to the input framerate\n",
    "print_input = True # very computationally expensive, set scale_down to > 4\n",
    "print_output = True # very computationally expensive, set scale_down to > 4\n",
    "scale_down = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the input file\n",
    "input_stream = cv.VideoCapture(input_video)\n",
    "if (input_stream.isOpened() == False): \n",
    "      print(\"Error while opening the input video stream\")\n",
    "\n",
    "# get the input's properties\n",
    "frame_num = int(input_stream.get(cv.CAP_PROP_FRAME_COUNT))\n",
    "height = int(input_stream.get(cv.CAP_PROP_FRAME_HEIGHT) / 2)\n",
    "width  = int(input_stream.get(cv.CAP_PROP_FRAME_WIDTH))\n",
    "fps = int(input_stream.get(cv.CAP_PROP_FPS))\n",
    "\n",
    "print(\"Video Info:\")\n",
    "print(\"   Frames: \" + str(frame_num))\n",
    "print(\"   Dimensions: \" + str(height * 2) + \"x\" + str(width))\n",
    "print(\"   Framerate: \" + str(fps) + \" fps\")\n",
    "\n",
    "millis_per_frame = 1000 / fps\n",
    "\n",
    "# initialize the widgets\n",
    "image_in = widgets.Image()\n",
    "image_out = widgets.Image()\n",
    "\n",
    "queue_status = widgets.FloatProgress(description = 'Queue:', value = 0.0, min = 0.0, max = 1.0)\n",
    "\n",
    "if print_input:\n",
    "    images = [image_in, image_out]\n",
    "else:\n",
    "    images = [image_out]\n",
    "\n",
    "image_box = widgets.HBox(images)\n",
    "\n",
    "# initialize the queue\n",
    "queue = Queue(maxsize = queue_size)\n",
    "\n",
    "# initialize the two threads\n",
    "thread1 = threading.Thread(target = waiter)\n",
    "thread2 = threading.Thread(target = submitter)\n",
    "\n",
    "# start displaying the widgets\n",
    "display(queue_status)\n",
    "display(image_box)\n",
    "\n",
    "# start the threads\n",
    "thread1.start()\n",
    "thread2.start()\n",
    "\n",
    "# wait for the threads to complete\n",
    "queue.join()\n",
    "thread1.join()\n",
    "thread2.join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
