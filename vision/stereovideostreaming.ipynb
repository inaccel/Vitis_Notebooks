{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import inaccel.coral as inaccel\n",
    "import numpy as np\n",
    "# from IPython.display import Video, HTML\n",
    "# import math\n",
    "# from matplotlib import pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "# from ipywebrtc import ImageRecorder, VideoStream\n",
    "import PIL.Image\n",
    "import io\n",
    "from tqdm import tqdm\n",
    "import threading\n",
    "from queue import Queue\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ndarrays for the static parameters of the request\n",
    "# To help with scheduling we create one copy of each array for each request\n",
    "req_num = 4\n",
    "cameraMA_l = []\n",
    "cameraMA_r = []\n",
    "distC_l = []\n",
    "distC_r = []\n",
    "irA_l = []\n",
    "irA_r = []\n",
    "bm_state_arr = []\n",
    "for j in range(req_num):\n",
    "    cameraMA_l.append(inaccel.array([933.173, 0.0, 663.451, 0.0, 933.173, 377.015, 0.0, 0.0, 1.0], dtype=np.float32))\n",
    "    cameraMA_r.append(inaccel.array([933.467, 0.0, 678.297, 0.0, 933.467, 359.623, 0.0, 0.0, 1.0], dtype=np.float32))\n",
    "\n",
    "    distC_l.append(inaccel.array([-0.169398, 0.0227329, 0.0, 0.0, 0.0], dtype=np.float32))\n",
    "    distC_r.append(inaccel.array([-0.170581, 0.0249444, 0.0, 0.0, 0.0], dtype=np.float32))\n",
    "\n",
    "    irA_l.append(inaccel.array([0.0011976323, -0.0000000019, -0.8153011732, 0.0000000007, 0.0011976994, \\\n",
    "                               -0.4422348617,  0.0000126839,  0.0000001064, 0.9913820905], dtype=np.float32))\n",
    "    irA_r.append(inaccel.array([0.0011976994,  0.0000000000, -0.8047567905, -0.0000000000, 0.0011976994, \\\n",
    "                               -0.4420566166, -0.0000000000, -0.0000001064,  1.0000392898], dtype=np.float32))\n",
    "\n",
    "    bm_state_arr.append(inaccel.array([0, 15, 31, 15, 0, 48, 20, 15, 16, 3, 0], dtype=np.int32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The submitter thread reads frames from the video stream, converts them to the sizes that match the kernel,\n",
    "# creates the requests and submits them to Coral, and then fills the queue\n",
    "def submitter():\n",
    "    for i in range(frame_num):\n",
    "        # try to read a frame\n",
    "        ret, frame = input_stream.read()\n",
    "        if(ret==False):\n",
    "            queue.put((None,None,None,None,None))\n",
    "            break\n",
    "            \n",
    "        # turn the frame into two inaccel ndarrays, one for the left and one for the right image\n",
    "        frame_left = cv.cvtColor(cv.resize(frame[:,:width,:], (1280, 720)), cv.COLOR_BGR2GRAY)\n",
    "        frame_right = cv.cvtColor(cv.resize(frame[:,width:,:], (1280, 720)), cv.COLOR_BGR2GRAY)\n",
    "\n",
    "        # convert the two frames to inaccel ndarrays and allocate the result ndarray\n",
    "        left_mat = inaccel.array(frame_left)\n",
    "        right_mat = inaccel.array(frame_right)\n",
    "        disp_mat = inaccel.ndarray((720, 1280), dtype=np.uint16)\n",
    "\n",
    "        # create the request\n",
    "        req = inaccel.request('com.xilinx.vitis.vision.stereoBM')\n",
    "        req.arg(left_mat)\n",
    "        req.arg(right_mat)\n",
    "        req.arg(disp_mat)\n",
    "        req.arg(cameraMA_l[i%req_num])\n",
    "        req.arg(cameraMA_r[i%req_num])\n",
    "        req.arg(distC_l[i%req_num])\n",
    "        req.arg(distC_r[i%req_num])\n",
    "        req.arg(irA_l[i%req_num])\n",
    "        req.arg(irA_r[i%req_num])\n",
    "        req.arg(bm_state_arr[i%req_num])\n",
    "        req.arg(np.int32(720))\n",
    "        req.arg(np.int32(1280))\n",
    "        \n",
    "        # try to submit the request\n",
    "        try:\n",
    "            session = inaccel.submit(req)\n",
    "        except RuntimeError:\n",
    "            print(\"Request Failed, ensure the Coral manager is running\")\n",
    "            queue.put((None,None,None,None,None))\n",
    "            break\n",
    "        \n",
    "        # check the queue status and if the queue is full wait\n",
    "        while queue.full():\n",
    "            time.sleep(0.01)\n",
    "            \n",
    "        # put the new session and arrays in the queue\n",
    "        queue.put((session,left_mat,right_mat,disp_mat,frame))\n",
    "        \n",
    "        # update the queue status\n",
    "        queue_status.value = queue.qsize()/queue_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def printer(sync=False):\n",
    "    for i in tqdm(range(frame_num)):\n",
    "        start = time.time()*1000\n",
    "        \n",
    "        # try to read from the queue\n",
    "        session,left_mat,right_mat,disp_mat,frame = queue.get()\n",
    "        if(session==None):\n",
    "            break\n",
    "        \n",
    "        # wait for the session to complete\n",
    "        inaccel.wait(session)\n",
    "        \n",
    "        # normalize the output array\n",
    "        disp_img = (disp_mat.view(np.ndarray)*(256.0 / 48.0) / (16.0)).astype(np.uint8)\n",
    "        disp_img = cv.resize(cv.cvtColor(disp_img, cv.COLOR_GRAY2BGR), (height,width))\n",
    "\n",
    "        # convert the array to an image and write it to the widget\n",
    "        disp_img = PIL.Image.fromarray(disp_img)\n",
    "        f = io.BytesIO()\n",
    "        disp_img.save(f, format='png')\n",
    "        image_out.value = f.getvalue()\n",
    "        image_out.width = int(width*4)\n",
    "        image_out.height = int(height*4)\n",
    "\n",
    "        # if print_input is true do the same for the input frame\n",
    "        if(print_input):\n",
    "            frame_img = PIL.Image.fromarray(frame)\n",
    "            f = io.BytesIO()\n",
    "            frame_img.save(f, format='png')\n",
    "            image_in.value = f.getvalue()\n",
    "            image_in.width = int(width*4)\n",
    "            image_in.height = int(height*2)\n",
    "        \n",
    "        \n",
    "        # explicitly delete the inaccel arrays\n",
    "        # this step is not necessary, as the garbage collector will delete them too\n",
    "        # but it helps free the corresponding device memory\n",
    "        del left_mat\n",
    "        del right_mat\n",
    "        del disp_mat\n",
    "        \n",
    "        # if sync is true, sleep until it's time for the next frame\n",
    "        if(sync):\n",
    "            while ((time.time()*1000) - start < millis_per_frame):\n",
    "                time.sleep(0.000001)\n",
    "        \n",
    "        # update queue status\n",
    "        queue.task_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "input_video = \"data/chair021.mp4\"\n",
    "output_video = \"data/output.mp4\"\n",
    "queue_size = 16 # not necessary, but it helps manage resources \n",
    "sync_output = False # force output framerate to be as close to the same as the input framerate\n",
    "print_input = False # very computationally expensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the input file\n",
    "input_stream = cv.VideoCapture(input_video)\n",
    "if (input_stream.isOpened()== False): \n",
    "      print(\"Error opening video stream or file\")\n",
    "\n",
    "# get the input's properties\n",
    "frame_num = int(input_stream.get(cv.CAP_PROP_FRAME_COUNT))\n",
    "height = int(input_stream.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
    "width  = int(input_stream.get(cv.CAP_PROP_FRAME_WIDTH)/2)\n",
    "fps = int(input_stream.get(cv.CAP_PROP_FPS))\n",
    "\n",
    "print(\"Video Info:\")\n",
    "print(\"   Frames: \" + str(frame_num))\n",
    "print(\"   Dimensions: \" + str(height) + \"x\" + str(width*2))\n",
    "print(\"   Framerate: \" + str(fps) + \" fps\")\n",
    "\n",
    "millis_per_frame = 1000/fps\n",
    "\n",
    "# initialize the widgets\n",
    "image_in = widgets.Image()\n",
    "image_out = widgets.Image()\n",
    "\n",
    "queue_status = widgets.FloatProgress(description='Queue:',value=0.0, min=0.0, max=1.0)\n",
    "\n",
    "if print_input:\n",
    "    images = [image_in,image_out]\n",
    "else:\n",
    "    images = [image_out]\n",
    "\n",
    "image_box = widgets.VBox(images)\n",
    "\n",
    "# initialize the queue\n",
    "queue = Queue(maxsize=queue_size)\n",
    "\n",
    "# initialize the threads\n",
    "thread1 = threading.Thread(target=printer, args=[sync_output])\n",
    "thread2 = threading.Thread(target=submitter)\n",
    "\n",
    "# start displaying the widgets\n",
    "display(queue_status)\n",
    "display(image_box)\n",
    "\n",
    "# start the threads\n",
    "thread1.start()\n",
    "thread2.start()\n",
    "\n",
    "# wait for the threads to complete\n",
    "queue.join()\n",
    "thread1.join()\n",
    "thread2.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
